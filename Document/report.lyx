#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass IEEEtran
\begin_preamble
% for subfigures/subtables
\ifCLASSOPTIONcompsoc
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\else
\usepackage[caption=false,font=footnotesize]{subfig}
\fi
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding default
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement tbh
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_title "Your Title"
\pdf_author "Your Name"
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle false
\pdf_quoted_options "pdfpagelayout=OneColumn, pdfnewwindow=true, pdfstartview=XYZ, plainpages=false"
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 0
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
This is a template LyX file for articles to be submitted to journals of
 the Institute of Electrical and Electronics Engineers (IEEE).
 For general info see 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://wiki.lyx.org/Examples/IEEE
\end_layout

\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
It is important that you use the correct document class options for your
 document..
 These are explained in the IEEEtran document: 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

http://mirror.ctan.org/macros/latex/contrib/IEEEtran/IEEEtran_HOWTO.pdf
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Title
Implementation and Analysis of Parallel Shortest Path Graph Algorithms
\end_layout

\begin_layout Author
Brandon Autrey, Anthony Bolton, Ryan Harrigan
\end_layout

\begin_layout Abstract
Finding the shortest path is very important in many applications.
 This is computed by graph algorithms which can be computationally intensive
 on large graphs or datasets.
 Computational speed is important for real-time applications such as pathing
 for games, traffic analysis for GPS systems, and geodetics.
 In this paper we explore the parallelization of A*, Dijkstra, and Bellman-Ford
 using OpenMP on an SMP architecture.
 The performance of these algorithms are compared against their serial versions
 to show their parallelization efficiency.
 These algorithms are then experimented on real datasets and generated datasets
 to show the shortest path.
 
\end_layout

\begin_layout Keywords
OpenMP, SMP, graph algorithms, shortest path, multithreading, Dijkstra’s,
 A*, Bellman-Ford, pathfinding, genetic algorithm
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
IEEEPARstart{
\end_layout

\end_inset

T
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}{
\end_layout

\end_inset

here
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 are many ways for graphs to be used.
 Depending on the purpose of the program, the same data can offer different
 insights for the user.
 As there are various ways to represent data, a slurry of algorithms are
 available for processing.
 This is interesting because the effectiveness of algorithms are dependent
 on data and vice versa.
 
\end_layout

\begin_layout Standard
Determining information from graphs is usually accomplished by one of two
 general approaches.
 Read-oriented processing usually does not alter vertices/edges.
 They usually run faster because writing values pauses the traversing process.
 Path processing is different because a separate memory-space is required
 to compute some values for decision-making.
 Many algorithms have been imagined to traverse graphs for different reasons.
 Such algorithms include Dijkstra’s, A*, Prim’s, and Floyd-Warshall’s.
 These algorithms were designed for a serial environment.
 When introduced to parallelism, many difficulties arise.
\end_layout

\begin_layout Standard
Read-oriented processing is fair because it usually splits the graph into
 equal parts for the cores to compute operations in parallel.
 Read-oriented processing generally does not have contention when performing
 operations from vertex/edge values because the outputs of threads do not
 conflict with other thread’s input.
 Shortest path processing, however, introduces most of the difficulty.
 Threads must share read/write access to shared nodes/edges and their synchroniz
ation tends to be serial in nature.
 Especially in dense graphs, shortest path processing has contention when
 updating adjacency lists.
 Both approaches have a variety of applications, but the prevalent concerns
 are focused on defining areas of possible contention when considered for
 parallelism.
\end_layout

\begin_layout Standard
Parallelizing graph search algorithms is challenging.
 Challenges are often addressed by the irregularity of data, locality of
 data in terms of the shared global data among threads, and the partitioning
 of data among threads.
 Irregular data causes latency for datum identification.
 Data locality is difficult to predict, especially when predefined code
 is absent, because locality often requires computing relationship among
 many other nodes/edges.
 Partitioning of data computation requires careful definitions of memory
 access.
 Determining the grain of parallelism and boundaries of dependent node/edge
 values tend to make programming complex because of these general challenges.
\end_layout

\begin_layout Standard
This paper will juxtapose serial and parallel implementations of Dijkstra’s,
 A*, Floyd-Warshal’s, and genetic algorithms.
 These algorithms have unique properties in parallel environments and can
 improve many real-world applications.
 To demonstrate of these algorithms, this paper will experiment on graph
 generation for games, road maps of the United States, and LiDAR terrain
 data.
 These datasets also have different properties and such will show various
 runtimes.
\end_layout

\begin_layout Standard
Implementations in this paper will often use OpenMP.
 OpenMP is a set of commands that was intended to ease parallelization.
 Just like POSIX threads, it is formatted to work on SMP machines, however,
 it can be incorporated in distributed environments.
 For the sake of brevity, implementations of algorithms will be limited
 to SMP environments.
\end_layout

\begin_layout Standard
OpenMP takes advantage of global memory available to the computing nodes;
 allowing each node to be updated as shared memory changes.
 An OpenMP application begins with the master thread.
 When the program encounters a parallel region construct, OpenMP automatically
 creates and distributes threads to computing nodes, overhead requiring
 time before parallel computation begins.
 This time must be considered for time performance and is strongly suggested
 that the parallel sections have large demand 
\begin_inset CommandInset citation
LatexCommand cite
key "citutor"

\end_inset

.
 At the end of the parallel region, the created threads are stopped and
 the master thread continues running.
 OpenMP specifies parallel regions by pragmas, a directive based standard,
 so that the source code combines serial and parallel code.
 The program be compiled with or without the /openmp compiler option.
 If it is compiled without it, then the pragmas are ignored and the program
 behaves as entirely serial.
 
\end_layout

\begin_layout Section
Related Work
\end_layout

\begin_layout Standard
Previously an attempt to parallelize Dijkstra’s using OpenMP gained a 10%
 speedup by making it parallel.
 This algorithm is a difficult to parallelize to gain a significant speedup
 because lots of time is being spent on parallelization and synchronization
 than is actually being spent on the execution of code.
 The algorithm is not suited for parallelism because it relies on priority
 queues 
\begin_inset CommandInset citation
LatexCommand cite
key "Jasika-2012-dijkstra"

\end_inset

.
 Since the priority queue is the bottleneck in the parallelization of this
 algorithm, this paper will attempt an implementation of parallelizing the
 priority queue.
 
\end_layout

\begin_layout Standard
Without even parallelizing the code, there are some optimizations that can
 be made to the A* algorithm.
 For example, research has been done discussing the use of precomputed paths
 for commonly used paths, or using particular landmarks and precalculating
 paths between them.
 Additionally, A* can be modified to be a bidirectional search, wherein
 two searches are conducted “simultaneously” starting at both the origin
 node and the target node, branching out until they meet in the middle.
 The word “simultaneously” is in quotes because while it may appear like
 the bidirectional search is happening concurrently, with only one thread
 and/or processor the calculations are still happening serially, alternating
 between calculating the path from the start node and the path from the
 target node.
 Andrew Goldberg, principal researcher at Microsoft Research Silicon Valley,
 along with other colleagues have published several papers on improving
 various shortest path algorithms 
\begin_inset CommandInset citation
LatexCommand cite
key "Goldberg-2005-microsoftTechReportA*"

\end_inset

.
 They have used data sets like the North American road network (which is
 almost 30 million nodes) so it is clear why it is important that they optimize
 the time efficiency of their shortest path algorithms.
 They have shown a variety of algorithms traversing this network with randomly
 selected “origin” and “destination” nodes, and it shows the variety of
 routes by which these algorithms traverse the network.
 Clearly, some of them are not very efficient because they visit nodes that
 do not need to be considered in the first place.
 The image below is that of a bidirectional search performed with Dijkstra’s
 algorithm with the green area emanating from the origin node and the blue
 area emanating from the target node 
\begin_inset CommandInset citation
LatexCommand cite
key "Chang-2009-shortestPath"

\end_inset

.
 Once they find a meeting point, the path has been calculated and the search
 stops.
 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename D:/Dropbox/Parallel Programming Project/Anthony/Images for Reports-Presentation/bidirectionaldijkstra.png
	scale 80

\end_inset


\end_layout

\begin_layout Standard
The A* algorithm is essentially Dijkstra’s algorithm with an admissible
 heuristic (also called an optimistic heuristic) for searching, which means
 it never overestimates the cost of reaching the goal - it’s always an underesti
mate of the cost or the exact cost (this paper explores the Euclidean distance
 as the cost) 
\begin_inset CommandInset citation
LatexCommand cite
key "Eranki-2002-Astar"

\end_inset

.
 The following image is the same network but now with a bidirectional A*
 algorithm performed along with precalculated landmarks 
\begin_inset CommandInset citation
LatexCommand cite
key "Eranki-2002-Astar"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename D:/Dropbox/Parallel Programming Project/Anthony/Images for Reports-Presentation/astar-landmarks.png
	scale 80
	clip

\end_inset


\end_layout

\begin_layout Standard
Though this implementation of the A* algorithm also involves precalculated
 landmarks, the reader can see that a great deal of computation and “unnecessary
 nodes” are ignored when using this P2P (point-to-point) search algorithm
 versus a simple Dijkstra’s.
\end_layout

\begin_layout Section
Parallel Algorithm Analysis
\end_layout

\begin_layout Subsection
Parallel Dijkstra Algorithm
\end_layout

\begin_layout Standard
The Dijkstra’s algorithm is a graph search algorithm that involves finding
 the single-source shortest path with a graph of non-negative weights.
 It is widely used in applications where the destination node is not necessary
 known before the algorithms starts.
 An application is for finding routes within networks.
 This algorithm keeps two sets, the set of nodes it has already checked
 and the set of nodes that it has not checked.
 When searching the algorithm searches every neighboring vertex from the
 previously checked vertex.
 This results in checking every vertex in a circle almost, until the destination
 vertex is found.
 The approach used was to parallelize Dijkstra was to distribute the threads
 along the current source node to find the closest neighboring node with
 the least weight value.
 The least weight is then distributed to to the other nodes and then the
 source node is updated to be the least weight.
 This is continued until the destination node is found or until all the
 nodes in the graph are searched.
 
\end_layout

\begin_layout Subsection
Parallel A* Algorithm
\end_layout

\begin_layout Standard
The A* algorithm is a popular pathfinding algorithm used to find the shortest
 distance between two points and is actually a modification of Dijkstra's
 algorithm.
 The A* algorithm uses a heuristic based on estimating the distance from
 any searched node to the desired target node, and the A* algorithm can
 be made to be Dijkstra's algorithm simply by setting the heuristic cost
 to zero for all the nodes.
 The A* algorithm requires a priority queue for the optimal choices currently
 held to be possible paths from the origin node to the target node, and
 when one path 'deeper' in the queue is discovered to be shorter than the
 shortest path so far, it climbs to the head of the priority queue.
 Shortest paths algorithms like A* are types of combinatorial optimization
 problems that can be useful for real-world applications like route planning
 for shipping paths.
 Using multiple threads and altering the algorithm to work more efficiently
 in a parallel environment, we will show that the parallelized version of
 the A* algorithm is more efficient and can be used to compute the shortest
 path very quickly for large sets of data.
 For efficiency of runtime, it is important that your graph be connected
 (i.e., that all your nodes are connected to one another by way of some path
 in the graph and that no nodes are isolated) or that at least your start
 node and your end node are part of the same "connected component" of the
 graph.
 If your start node and end node are NOT part of the same connected component,
 your search (bidirectional or otherwise) will search through the ENTIRE
 search space within the connected component(s) of the graph that has your
 starting node (and within the full connected component that has your ending
 node, if doing a bidirectional search) - a very costly operation.
 The pseudocode for the serial version implementation of the A* algorithm
 used in this paper is as follows:
\end_layout

\begin_layout Standard
For the purposes of parallelization, it will be necessary to create a concurrent
 priority queue data structure, as well as a parallelized dynamic array
 (Java was utilized, so for the serial version of the algorithm, ArrayList
 was used for this purpose).
 A trivial way to parallelize this algorithm a bit would involve parallelizing
 a bidirectional search involving only two processors and two threads, initially.
 One thread will be responsible with searching starting from the origin
 node, and the other thread will be responsible for searching starting with
 the destination node.
 When one of the threads has a path that exceeds half the heuristic distance
 to the other thread’s origin node, it will begin to check whether the nodes
 it’s adding to the path have also been added to the other thread’s path.
\end_layout

\begin_layout Standard
Additionally, the for-loop for searching a node’s neighbors can be parallelized
 easily in OpenMP with their pragma-for-loop abilities, so it will take
 the threads available to your computer and put them to work in the for-loop.
 In general, the work of the for-loop can be divided amongst individual
 threads waiting to perform calculation-work in a thread pool, and then
 when their calculation is complete, they can return to the thread pool,
 awaiting being used for the next for-loop of either of the bidirectional
 searches.
 Additionally, there is the possibility of having a separate thread go through
 the combined set of nodes included so-far in the two paths (since a bidirection
al search will be performed) to stop the searches once it encounters a node
 that states it is in both thread’s paths.
 It is the attempt of this paper to show that these changes to the algorithm
 will result in an optimized runtime of the algorithm on large datasets.
\end_layout

\begin_layout Subsection
Parallel Bellman-Ford Algorithm
\end_layout

\begin_layout Section
Experimentation and Testing
\end_layout

\begin_layout Standard
A paper written by Luis Henrique Oliveira Rios and Luiz Chaimowicz of the
 Department of Computer Science of Federal University of Minas Gerais in
 Brazil suggests a method of parallelizing the A Star search algorithm that
 uses a bidirectional search, much like our proposed method.
 Their version, called Parallel New Bidirectional A* 
\begin_inset CommandInset citation
LatexCommand cite
key "riospnba"

\end_inset

, proposes that rather than having an 'open Nodes' priority queue that contains
 the nodes on the frontier, each of two threads (one starting at the goal
 toward the starting node and the other from the starting node to the goal
 node) contains its own open Nodes priority queue.
 Additionally, each thread maintains its own F, G, and H function values
 for its nodes, but instead of holding an array for ‘closed Nodes’ that
 holds the Nodes that have already been expanded, the two threads have shared
 access to a set of nodes, M, that contains all the Nodes that are “in the
 middle”.
 Initially, all of the nodes are placed in this set, M, and as they are
 expanded (meaning, their neighbors are visited and exhausted), they are
 removed from the set M.
 L is also a variable that is shared by both threads - it is also read and
 written by both threads.
 It represents the cost of the best solution found by the algorithm so far
 and is initialized with the value of infinity.
 The source code available in the paper which was cited is represented by
 the pseudocode pictured below.
 In this other paper, the group used the C++ programming language along
 with the pthreads library.
 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename D:/Dropbox/Parallel Programming Project/PNBA.png
	scale 80

\end_inset


\end_layout

\begin_layout Standard
In this paper’s implementation, the Java programming language was used with
 its own natural threading capability.
 Two threads were created much like the pseudocode above suggests, with
 all subscripts (‘1s’ and ‘2s’) switching (becoming ‘2s’ and ‘1s’) for the
 opposite thread (thread 1 starting from the start node and seeking the
 goal node, and thread 2 starting from the goal node and seeking the start
 node).
 
\end_layout

\begin_layout Standard
The termination condition is that there are no more Nodes in the shared
 M set of “middle Nodes” - this is admissible because even if a node is
 searched twice by both threads, the search is guaranteed to choose the
 Nodes that lead to the smallest L value.
 
\end_layout

\begin_layout Standard
Unfortunately, the implementations of the above pseudocode proved to perform
 worse than their serial, unidirectional counterparts.
 This may be due to the overhead of creating the Threads initially, or locking
 the critical section with a Semaphore.
 Or, this may have had to do with the fact that the shared variables M and
 L were being accessed by the threads by a much larger component that was
 passed into the Threads as arguments, and was set to volatile.
 Such a large component (the GraphGUI class itself) with so many intricate,
 threaded parts (it also handled the GUI creation, so painting and repainting
 the screen) probably should not have been treated as volatile.
 Most likely the speed decrease was due to the reasons above, but otherwise
 it seems, logically, that the implementation of the pseudocode above should
 have been sound otherwise.
 The next several images will showcase the decrease in speed, as opposed
 to the expected increase that parallelizing the A* algorithm should have
 produced.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename D:/Dropbox/Parallel Programming Project/serialAStar.png
	scale 30

\end_inset


\end_layout

\begin_layout Standard
As the reader will note, the A* search started in the middle of the graph
 and the goal node was in the bottom right corner.
 The red lines represent failed paths, whereas the black line represents
 the actual shortest path computed.
 At the bottom of the GUI window note that the execution time (of the actual
 A* algorithm itself, and not in drawing to the GUI) is approximately 0.4477
 seconds.
 The equivalent parallelized A* search with the same starting and ending
 Node is pictured below.
 
\end_layout

\begin_layout Standard
The reader will now note that the search space has increased slightly (because
 the goal node is now seeking the start node as well, so it searches around
 itself), and the path is visibly incorrect.
 The process for drawing the path became disjoint, but the portion going
 from the goal node to the start node is correct.
 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename D:/Dropbox/Parallel Programming Project/parallelAStar.png
	scale 30

\end_inset


\end_layout

\begin_layout Standard
Also of interest is that the execution time (simply for A* and not for drawing
 the GUI), is now 2.9745 seconds, and in the console window you can see the
 time taken by BOTH threads is greater than the time the single, unidirectional
 A* search endured.
 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename D:/Dropbox/Parallel Programming Project/serialDijkstra.png
	scale 30

\end_inset


\end_layout

\begin_layout Standard
Recall that A* search becomes equivalent to Dijkstra’s search algorithm
 when the heuristic is set to 0.
 Above you can not that Dijkstra’s takes approximately .7 seconds when executed
 serially.
 However, as the picture below will attest, it took almost one order of
 magnitude longer (4.39 seconds) for the two threads to execute.
 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename D:/Dropbox/Parallel Programming Project/ParallelDijkstra.png
	scale 30

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Remember though that your final submission is supposed to have all the bibliogra
phy entries embedded in the LaTeX-file.
 This means you eventually have to copy the .bbl file into the latex file
 and remove the bibtex lines.
\end_layout

\end_inset


\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "report_ref"
options "IEEEtran"

\end_inset


\end_layout

\end_body
\end_document
